{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script uses hotel reviews of Helsinki(Norway) in Tripadvisor website to demonstrate sentiment analysis.\n",
    "### 1st section\n",
    "The statistics data of Helsinki hotel reviews after preprocessing. The preprocessing includes \"duplication elimination\", \"review record tuple with missing review\".\n",
    "### 2nd section\n",
    "In 2nd section, applying machine learning and natural language processing technologies to these processed data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext, SparkSession\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"sentiment analysis demo\").config(\n",
    "            \"spark.some.config.option\", \"sentAnalysis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source = spark.read.json(\"../reviewData/Tripadvisor/005_Helsinki_Tripadvisor.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### display the first review item, the schema of dataframe shows below:\n",
    "\n",
    "\"hotelStars\" attribute means the hotel is on which level, one-star, two-star, three-star.....\n",
    "\"score\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': Row($oid='598c7e7e9b1f26716b0b33c2'),\n",
       " 'date': None,\n",
       " 'hotelLocation': 'Pieni Roobertinkatu 1-3, Helsinki 00130, Finland',\n",
       " 'hotelName': ' Hotel Lilla Roberts ',\n",
       " 'hotelStars': '4.5',\n",
       " 'hotelUrl': 'https://www.tripadvisor.com/Hotel_Review-g189934-d7940665-Reviews-Hotel_Lilla_Roberts-Helsinki_Uusimaa.html',\n",
       " 'review': 'Lilla Roberts is a brand new Art Deco creation. Materials and craftsmanship of very high quality, built to last and age well. A very welcome and needed addition to the not-so-crowded Helsinki luxury hotel scene. Goes to the very top.Thoughtful details in the room and very comfortable beds, probably the best mattress in Helsinki.Gym yet to open in August 15, though you can use one in the sister hotel.',\n",
       " 'score': 5.0,\n",
       " 'title': 'Breathes quality and style',\n",
       " 'url': 'https://www.tripadvisor.com/ShowUserReviews-g189934-d7940665-r298267980-Hotel_Lilla_Roberts-Helsinki_Uusimaa.html',\n",
       " 'userId': 'Janos R'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source.first().asDict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The number of reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23410"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce duplicate reviews items, and eliminate record items with missing info, including \"hotelUrl\", \"review\", \"usererId\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23231"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = source.drop_duplicates()\n",
    "data = data.filter(\"hotelLocation is not Null\")\n",
    "data = data.filter(\"hotelName is not Null\")\n",
    "data = data.filter(\"hotelStars is not Null\")\n",
    "data = data.filter(\"review is not Null\")\n",
    "data = data.filter(\"score is not Null\")\n",
    "data = data.filter(\"url is not Null\")\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get Helsinki Hotel basic statistics, the distribution for different hotel stars\n",
    "[0,1], (1,2], (2,3), [3, 4), [4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = source.select(\"review\", \"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(review='Lilla Roberts is a brand new Art Deco creation. Materials and craftsmanship of very high quality, built to last and age well. A very welcome and needed addition to the not-so-crowded Helsinki luxury hotel scene. Goes to the very top.Thoughtful details in the room and very comfortable beds, probably the best mattress in Helsinki.Gym yet to open in August 15, though you can use one in the sister hotel.', score=5.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.filter(\"review is not Null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.filter(\"score is not Null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasplits = data.randomSplit([0.8, 0.2], 24)\n",
    "train, test = datasplits[0], datasplits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18643"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.0, 4.0, 5.0, 4.0, 4.0, 5.0, 5.0, 3.0, 5.0, 5.0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.select(\"score\").rdd.flatMap(lambda x: x).collect()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.feature import IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remove_spl_char_regex = re.compile('[%s]' % re.escape(string.punctuation))  # regex to remove special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = [u'rt', u're', u'i', u'me', u'my', u'myself', u'we', u'our', u'ours', u'ourselves', u'you', u'your',\n",
    "             u'yours', u'yourself', u'yourselves', u'he', u'him', u'his', u'himself', u'she', u'her', u'hers',\n",
    "             u'herself', u'it', u'its', u'itself', u'they', u'them', u'their', u'theirs', u'themselves', u'what',\n",
    "             u'which', u'who', u'whom', u'this', u'that', u'these', u'those', u'am', u'is', u'are', u'was', u'were',\n",
    "             u'be', u'been', u'being', u'have', u'has', u'had', u'having', u'do', u'does', u'did', u'doing', u'a',\n",
    "             u'an', u'the', u'and', u'but', u'if', u'or', u'because', u'as', u'until', u'while', u'of', u'at', u'by',\n",
    "             u'for', u'with', u'about', u'against', u'between', u'into', u'through', u'during', u'before', u'after',\n",
    "             u'above', u'below', u'to', u'from', u'up', u'down', u'in', u'out', u'on', u'off', u'over', u'under',\n",
    "             u'again', u'further', u'then', u'once', u'here', u'there', u'when', u'where', u'why', u'how', u'all',\n",
    "             u'any', u'both', u'each', u'few', u'more', u'most', u'other', u'some', u'such', u'no', u'nor', u'not',\n",
    "             u'only', u'own', u'same', u'so', u'than', u'too', u'very', u's', u't', u'can', u'will', u'just', u'don',\n",
    "             u'should', u'now']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokenize函数对tweets内容进行分词\n",
    "def tokenize(text):\n",
    "    tokens = []\n",
    "#     print(text)\n",
    "#     text = text.encode('ascii', 'ignore')  # to decode\n",
    "#     print(\"-------\")\n",
    "#     print(text)\n",
    "    text = remove_spl_char_regex.sub(\" \", text)  # Remove special characters\n",
    "    text = text.lower()\n",
    "\n",
    "    for word in text.split():\n",
    "        if word not in stopwords \\\n",
    "                and word not in string.punctuation \\\n",
    "                and len(word) > 1 \\\n",
    "                and word != '``':\n",
    "            tokens.append(word)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def doc2vec(document):\n",
    "    # 100维的向量\n",
    "    doc_vec = np.zeros(100)\n",
    "    tot_words = 0\n",
    "\n",
    "    for word in document:\n",
    "        try:\n",
    "        # 查找该词在预训练的word2vec模型中的特征值\n",
    "            vec = np.array(lookup_bd.value.get(word)) + 1\n",
    "            # print(vec)\n",
    "            # 若该特征词在预先训练好的模型中，则添加到向量中\n",
    "            if vec != None:\n",
    "                doc_vec += vec\n",
    "                tot_words += 1\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    vec = doc_vec / float(tot_words)\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lookup = spark.read.parquet(\"/home/yi/Music/Sentiment-Analysis/word2vecM_simple/data\").alias(\"lookup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- word: string (nullable = true)\n",
      " |-- vector: array (nullable = true)\n",
      " |    |-- element: float (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lookup.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lookup_bd = sc.broadcast(lookup.rdd.collectAsMap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yi/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "for row in train.collect():\n",
    "#     print(\"review: \", row[\"review\"])\n",
    "    token_text = tokenize(row[\"review\"])# 规范化评论文本，进行分词\n",
    "#     print(\"segmentation\")\n",
    "#     print(token_text)\n",
    "    review_text = doc2vec(token_text)# 将文本转换为向量\n",
    "#     print(review_text)\n",
    "    trn_data.append(LabeledPoint(row[\"score\"], review_text))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabeledPoint(1.0, [nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trnData = sc.parallelize(trn_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tst_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yi/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "for row in test.collect():\n",
    "#     print(\"review: \", row[\"review\"])\n",
    "    token_text = tokenize(row[\"review\"])# 规范化评论文本，进行分词\n",
    "#     print(\"segmentation\")\n",
    "#     print(token_text)\n",
    "    review_text = doc2vec(token_text)# 将文本转换为向量\n",
    "#     print(review_text)\n",
    "    tst_data.append(LabeledPoint(row[\"score\"], review_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(4.0, [nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan])]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tst_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tstData = sc.parallelize(tst_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train random forest classifier model\n",
    "model = RandomForest.trainClassifier(trnData, numClasses=6, categoricalFeaturesInfo={},\n",
    "                                     numTrees=3, featureSubsetStrategy=\"auto\",\n",
    "                                     impurity='gini', maxDepth=4, maxBins=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict the rest 20% test data\n",
    "predictions = model.predict(tstData.map(lambda x: x.features))\n",
    "labelsAndPredictions = tstData.map(lambda lp: lp.label).zip(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testErr = labelsAndPredictions.filter(lambda v: v[0] != v[1]).count() / float(tstData.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.5892394122731202\n",
      "Learned classification tree model:\n",
      "TreeEnsembleModel classifier with 3 trees\n",
      "\n",
      "  Tree 0:\n",
      "    Predict: 4.0\n",
      "  Tree 1:\n",
      "    Predict: 4.0\n",
      "  Tree 2:\n",
      "    Predict: 4.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Test Error = ' + str(testErr))\n",
    "print('Learned classification tree model:')\n",
    "# print the random forest classifier model\n",
    "print(model.toDebugString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using SVM methods\n",
    "from pyspark.mllib.classification import SVMWithSGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# has error,\n",
    "# svm = SVMWithSGD.train(sc.parallelize(tst_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[56] at parallelize at PythonRDD.scala:475"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize(tst_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using bag of words method\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2), max_features=100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-47-ca15ba20a31b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-47-ca15ba20a31b>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    vectorizer.fit(trnData[)\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "vectorizer.fit(trnData[)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trnData.map(lambda x : x[0]).toList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainScores = [i.score for i in train.select(\"score\").collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainScores[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainReviews = [i.review for i in train.select(\"review\").collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'+ Good location. Delicious breakfast. Convenient parking. This hotel is good for travelers and business meetings.- Sanitary equipment was not working. Standing water was In the sink. The minibar was empty.'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainReviews[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec = vectorizer.fit_transform(trainReviews).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec[100][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testReviews = [i.review for i in test.select(\"review\").collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testScore = [i.score for i in test.select(\"score\").collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=100000, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example1 = trainReviews[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(See in English below)Yöpyminen oli hyvitys täysin pilalle menneestä matkasta, koska hotelli halusi näyttää, että pystyvät parempaan. Hyvitys hyvitettiin hyvityksellä, joka hyvitettiin hyvityksellä ja jossa epäonnistuttiin. Yhdessäkään asiassa ei oltu otettu opiksi ensimmäisestä matkasta. Nyt on siis kaksi kertaa kokeiltu ja voin sanoa, etten suosittele mistään hinnasta. Palvelut eivät keskustele keskenään ja jäävät irrallisiksi kikkareiksi. Siitä syystä palveluiden välille tulee katkoksia, joista asiakas kärsii. Työntekijät hoitavat oman \"tonttinsa\", mutta eivät mieti, miten asia näyttäytyy asiakkaalle. Hotellissa kukaan ei ota viimeistä vastuuta ja huolehdi, että lopulta asiat onnistuvat. Puitteet olisivat huikeat ja mahdollisuudet olisivat rajattomat, mutta koska hotellia ei osata johtaa, ei noita mahdollisuuksia saada käyttöön. Prosessit ontuvat ja pahasti. The hotel itself is fine and new but everything else doesn\\'t work. Don\\'t bother. This trip was a compensation of the other trip which didn\\'t go well. Clarion wanted to show us that they could be better than last time but unfortunately they hadn\\'t learnt a thing from the past. We were promised a room upgrade but we got same room just one floor upper. When I asked about our uppgrade I got a mean comment that \"you got the room a floor upper.\" Yes, but that\\'s not an upgrade. My brother stayed with his girlfriend at the same time in the same hotel two nights and they had a standard room while we had a deluxe. Even they got their standard room higher than what we got and the hotel called it \\'upgrade\\'. The hotel was almost empty then. I even check the possibility to book the upgrated rooms and they were available. I would have understand if the hotel was fully booked! I really thought they will take a good care of us this time but now I just think this is a big bluff. The hotel is fine with it\\'s roof top bar and pool but everything else is terrible from cleaning to service. In our room there were four candies and a note \"welcome again\" in the room. I had informed my allergies when we booked and I was promised they are going to be take seriously this time. The four candies has milk I\\'m allergic to... I was told we got a \\'plus package\\' in the room or something like that. Are you serious that there are four candies in room then?! The room wasn\\'t cleaned even I asked for that before I booked the room. The we waited 2 hours in the lobby for the cleaning. And still it wasn\\'t cleaned propperly. There had actually appeared new body hair. It felt like the cleaning staff got feedback and wanted to revenge. There wasn\\'t anything new in this trip. Clarion wanted to compensate the cleaning and wanted to serve a dinner for us. But it was a problem because my brother and his girlfriend was coming too so the hotel could just offer our dinner (for two, not for four). I didn\\'t want to go because the last time was so horrible in the restaurant but my man talked me over. This time the food didn\\'t include anything I\\'m allergic to but it wasn\\'t a restaurant dish... Even I could cook better... We ate just the main course and one drinks, still you couldn\\'t offer the dinner to my brother and his girlfriend too although we were promised a three dish dinner with drinks for two... But the best thing comes till the end. We had to pay the dinner. The information didn\\'t go from the reception to restaurant that we were supposed to get it, not pay. And when it comes time for some breakfast: my allergies supposed to be informed to the restaurant and yes they somehow where. But because my allergies are very serious I have to double check, especially in cases the trust has gone ages ago. I got a seperate breakfast which had been done just for me. That\\'s a good thing. BUT: I checked three dishes in and two of them included food I\\'m allergic to. The best was that I\\'m allergic to eggs and I got a boiled egg on my plate. The person who was in charge of my breakfast even yelled at me. She couldn\\'t handle her own mistakes. That didn\\'t feel nice. I\\'m very dissapointed that Clarion couldn\\'t do anything better since the last time. Still I even brought two new customers to them, and the thanks were these... I won\\'t be using this/these hotels no longer, and I can\\'t recommend anyone staying in this hotel.'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " See in English below Y pyminen oli hyvitys t ysin pilalle menneest  matkasta  koska hotelli halusi n ytt    ett  pystyv t parempaan  Hyvitys hyvitettiin hyvityksell   joka hyvitettiin hyvityksell  ja jossa ep onnistuttiin  Yhdess k  n asiassa ei oltu otettu opiksi ensimm isest  matkasta  Nyt on siis kaksi kertaa kokeiltu ja voin sanoa  etten suosittele mist  n hinnasta  Palvelut eiv t keskustele kesken  n ja j  v t irrallisiksi kikkareiksi  Siit  syyst  palveluiden v lille tulee katkoksia  joista asiakas k rsii  Ty ntekij t hoitavat oman  tonttinsa   mutta eiv t mieti  miten asia n ytt ytyy asiakkaalle  Hotellissa kukaan ei ota viimeist  vastuuta ja huolehdi  ett  lopulta asiat onnistuvat  Puitteet olisivat huikeat ja mahdollisuudet olisivat rajattomat  mutta koska hotellia ei osata johtaa  ei noita mahdollisuuksia saada k ytt  n  Prosessit ontuvat ja pahasti  The hotel itself is fine and new but everything else doesn t work  Don t bother  This trip was a compensation of the other trip which didn t go well  Clarion wanted to show us that they could be better than last time but unfortunately they hadn t learnt a thing from the past  We were promised a room upgrade but we got same room just one floor upper  When I asked about our uppgrade I got a mean comment that  you got the room a floor upper   Yes  but that s not an upgrade  My brother stayed with his girlfriend at the same time in the same hotel two nights and they had a standard room while we had a deluxe  Even they got their standard room higher than what we got and the hotel called it  upgrade   The hotel was almost empty then  I even check the possibility to book the upgrated rooms and they were available  I would have understand if the hotel was fully booked  I really thought they will take a good care of us this time but now I just think this is a big bluff  The hotel is fine with it s roof top bar and pool but everything else is terrible from cleaning to service  In our room there were four candies and a note  welcome again  in the room  I had informed my allergies when we booked and I was promised they are going to be take seriously this time  The four candies has milk I m allergic to    I was told we got a  plus package  in the room or something like that  Are you serious that there are four candies in room then   The room wasn t cleaned even I asked for that before I booked the room  The we waited   hours in the lobby for the cleaning  And still it wasn t cleaned propperly  There had actually appeared new body hair  It felt like the cleaning staff got feedback and wanted to revenge  There wasn t anything new in this trip  Clarion wanted to compensate the cleaning and wanted to serve a dinner for us  But it was a problem because my brother and his girlfriend was coming too so the hotel could just offer our dinner  for two  not for four   I didn t want to go because the last time was so horrible in the restaurant but my man talked me over  This time the food didn t include anything I m allergic to but it wasn t a restaurant dish    Even I could cook better    We ate just the main course and one drinks  still you couldn t offer the dinner to my brother and his girlfriend too although we were promised a three dish dinner with drinks for two    But the best thing comes till the end  We had to pay the dinner  The information didn t go from the reception to restaurant that we were supposed to get it  not pay  And when it comes time for some breakfast  my allergies supposed to be informed to the restaurant and yes they somehow where  But because my allergies are very serious I have to double check  especially in cases the trust has gone ages ago  I got a seperate breakfast which had been done just for me  That s a good thing  BUT  I checked three dishes in and two of them included food I m allergic to  The best was that I m allergic to eggs and I got a boiled egg on my plate  The person who was in charge of my breakfast even yelled at me  She couldn t handle her own mistakes  That didn t feel nice  I m very dissapointed that Clarion couldn t do anything better since the last time  Still I even brought two new customers to them  and the thanks were these    I won t be using this these hotels no longer  and I can t recommend anyone staying in this hotel \n"
     ]
    }
   ],
   "source": [
    "letters_only = re.sub(\"[^a-zA-Z]\", \" \", example1)\n",
    "print(letters_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lower_case = letters_only.lower()\n",
    "words = lower_case.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "print(len(stopwords.words(\"english\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = [i for i in words if not i in stopwords.words(\"english\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['see', 'english', 'pyminen', 'oli', 'hyvitys', 'ysin', 'pilalle', 'menneest', 'matkasta', 'koska', 'hotelli', 'halusi', 'n', 'ytt', 'ett', 'pystyv', 'parempaan', 'hyvitys', 'hyvitettiin', 'hyvityksell', 'joka', 'hyvitettiin', 'hyvityksell', 'ja', 'jossa', 'ep', 'onnistuttiin', 'yhdess', 'k', 'n', 'asiassa', 'ei', 'oltu', 'otettu', 'opiksi', 'ensimm', 'isest', 'matkasta', 'nyt', 'siis', 'kaksi', 'kertaa', 'kokeiltu', 'ja', 'voin', 'sanoa', 'etten', 'suosittele', 'mist', 'n', 'hinnasta', 'palvelut', 'eiv', 'keskustele', 'kesken', 'n', 'ja', 'j', 'v', 'irrallisiksi', 'kikkareiksi', 'siit', 'syyst', 'palveluiden', 'v', 'lille', 'tulee', 'katkoksia', 'joista', 'asiakas', 'k', 'rsii', 'ty', 'ntekij', 'hoitavat', 'oman', 'tonttinsa', 'mutta', 'eiv', 'mieti', 'miten', 'asia', 'n', 'ytt', 'ytyy', 'asiakkaalle', 'hotellissa', 'kukaan', 'ei', 'ota', 'viimeist', 'vastuuta', 'ja', 'huolehdi', 'ett', 'lopulta', 'asiat', 'onnistuvat', 'puitteet', 'olisivat', 'huikeat', 'ja', 'mahdollisuudet', 'olisivat', 'rajattomat', 'mutta', 'koska', 'hotellia', 'ei', 'osata', 'johtaa', 'ei', 'noita', 'mahdollisuuksia', 'saada', 'k', 'ytt', 'n', 'prosessit', 'ontuvat', 'ja', 'pahasti', 'hotel', 'fine', 'new', 'everything', 'else', 'work', 'bother', 'trip', 'compensation', 'trip', 'go', 'well', 'clarion', 'wanted', 'show', 'us', 'could', 'better', 'last', 'time', 'unfortunately', 'learnt', 'thing', 'past', 'promised', 'room', 'upgrade', 'got', 'room', 'one', 'floor', 'upper', 'asked', 'uppgrade', 'got', 'mean', 'comment', 'got', 'room', 'floor', 'upper', 'yes', 'upgrade', 'brother', 'stayed', 'girlfriend', 'time', 'hotel', 'two', 'nights', 'standard', 'room', 'deluxe', 'even', 'got', 'standard', 'room', 'higher', 'got', 'hotel', 'called', 'upgrade', 'hotel', 'almost', 'empty', 'even', 'check', 'possibility', 'book', 'upgrated', 'rooms', 'available', 'would', 'understand', 'hotel', 'fully', 'booked', 'really', 'thought', 'take', 'good', 'care', 'us', 'time', 'think', 'big', 'bluff', 'hotel', 'fine', 'roof', 'top', 'bar', 'pool', 'everything', 'else', 'terrible', 'cleaning', 'service', 'room', 'four', 'candies', 'note', 'welcome', 'room', 'informed', 'allergies', 'booked', 'promised', 'going', 'take', 'seriously', 'time', 'four', 'candies', 'milk', 'allergic', 'told', 'got', 'plus', 'package', 'room', 'something', 'like', 'serious', 'four', 'candies', 'room', 'room', 'cleaned', 'even', 'asked', 'booked', 'room', 'waited', 'hours', 'lobby', 'cleaning', 'still', 'cleaned', 'propperly', 'actually', 'appeared', 'new', 'body', 'hair', 'felt', 'like', 'cleaning', 'staff', 'got', 'feedback', 'wanted', 'revenge', 'anything', 'new', 'trip', 'clarion', 'wanted', 'compensate', 'cleaning', 'wanted', 'serve', 'dinner', 'us', 'problem', 'brother', 'girlfriend', 'coming', 'hotel', 'could', 'offer', 'dinner', 'two', 'four', 'want', 'go', 'last', 'time', 'horrible', 'restaurant', 'man', 'talked', 'time', 'food', 'include', 'anything', 'allergic', 'restaurant', 'dish', 'even', 'could', 'cook', 'better', 'ate', 'main', 'course', 'one', 'drinks', 'still', 'offer', 'dinner', 'brother', 'girlfriend', 'although', 'promised', 'three', 'dish', 'dinner', 'drinks', 'two', 'best', 'thing', 'comes', 'till', 'end', 'pay', 'dinner', 'information', 'go', 'reception', 'restaurant', 'supposed', 'get', 'pay', 'comes', 'time', 'breakfast', 'allergies', 'supposed', 'informed', 'restaurant', 'yes', 'somehow', 'allergies', 'serious', 'double', 'check', 'especially', 'cases', 'trust', 'gone', 'ages', 'ago', 'got', 'seperate', 'breakfast', 'done', 'good', 'thing', 'checked', 'three', 'dishes', 'two', 'included', 'food', 'allergic', 'best', 'allergic', 'eggs', 'got', 'boiled', 'egg', 'plate', 'person', 'charge', 'breakfast', 'even', 'yelled', 'handle', 'mistakes', 'feel', 'nice', 'dissapointed', 'clarion', 'anything', 'better', 'since', 'last', 'time', 'still', 'even', 'brought', 'two', 'new', 'customers', 'thanks', 'using', 'hotels', 'longer', 'recommend', 'anyone', 'staying', 'hotel']\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preprocess the review data\n",
    "def review_to_words(raw_review):\n",
    "#     print(\"raw review:  \", raw_review)\n",
    "#     print(type(raw_review))\n",
    "# 1. Remove non-letters\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", raw_review)\n",
    "# 2. convert to lower case, split into individual words\n",
    "    letters_only = letters_only.lower().split()\n",
    "# 3. in python, searching a set is much faster than searching a list, so convert the stopwords to a set.\n",
    "    words = set(stopwords.words(\"english\"))\n",
    "# 4. remove stop words\n",
    "    words = [i for i in letters_only if not i in words]\n",
    "# 5. join the words back into one string separated by space, and return the result.\n",
    "    result = \" \".join(words)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_trainReviews = [review_to_words(i) for i in trainReviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating the bag of words....\n"
     ]
    }
   ],
   "source": [
    "# Creating Features from a Bag of Words (Using scikit-learn)\n",
    "print(\"creating the bag of words....\")\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# countVectorizer is scikit-learn's bag of words tool\n",
    "vectorizer2 = CountVectorizer(analyzer=\"word\", tokenizer= None, \n",
    "                              preprocessor= None, stop_words= None, max_features= 5000)\n",
    "clean_trainReviews_features = vectorizer2.fit_transform(clean_trainReviews)\n",
    "clean_trainReviews_features = clean_trainReviews_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18643, 5000)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_trainReviews_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 2, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_trainReviews_features[1][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = vectorizer2.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aalto', 'ability', 'abit', 'able', 'abroad', 'absence', 'absent', 'absolute', 'absolutely', 'abundance', 'abundant', 'ac', 'accept', 'acceptable', 'accepted', 'access', 'accessed', 'accessibility', 'accessible', 'accidentally', 'accommodate', 'accommodated', 'accommodating', 'accommodation', 'accommodations', 'accomodate', 'accomodating', 'accomodation', 'accompanied', 'according', 'accordingly', 'account', 'accross', 'accurate', 'accustomed', 'across', 'act', 'action', 'active', 'activities', 'activity', 'actual', 'actually', 'adapter', 'adaptor', 'add', 'added', 'adding', 'addition', 'additional', 'additionally', 'address', 'addressed', 'adds', 'adequate', 'adequately', 'adjacent', 'adjoining', 'adjust', 'adjustable', 'adjusted', 'admit', 'admittedly', 'adult', 'adults', 'advance', 'advantage', 'advantages', 'adventure', 'advertise', 'advertised', 'advertises', 'advertising', 'advice', 'advisable', 'advise', 'advised', 'advising', 'advisor', 'affair', 'affect', 'afford', 'affordable', 'afield', 'afraid', 'afternoon', 'afterwards', 'age', 'aged', 'agency', 'agent', 'ages', 'ago', 'agree', 'agreed', 'ahead', 'ahjo', 'aid', 'aim', 'aimed']\n"
     ]
    }
   ],
   "source": [
    "print(vocab[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 aalto\n",
      "26 ability\n",
      "11 abit\n",
      "695 able\n",
      "22 abroad\n",
      "20 absence\n",
      "12 absent\n",
      "55 absolute\n",
      "508 absolutely\n",
      "23 abundance\n",
      "43 abundant\n",
      "129 ac\n",
      "35 accept\n",
      "152 acceptable\n",
      "39 accepted\n",
      "1027 access\n",
      "34 accessed\n",
      "15 accessibility\n",
      "180 accessible\n",
      "11 accidentally\n",
      "50 accommodate\n",
      "43 accommodated\n",
      "198 accommodating\n",
      "155 accommodation\n",
      "45 accommodations\n",
      "14 accomodate\n",
      "21 accomodating\n",
      "37 accomodation\n",
      "16 accompanied\n",
      "64 according\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sum up the counts of each vocabulary word\n",
    "dist = np.sum(clean_trainReviews_features, axis=0)\n",
    "\n",
    "# For each, print the vocabulary word and the number of times it \n",
    "# appears in the training set\n",
    "i = 0\n",
    "for tag, count in zip(vocab, dist):\n",
    "    if i == 30:\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "        print(count, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18643"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest = forest.fit(clean_trainReviews_features, trainScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean test reviews\n",
    "clean_test_reviews = [review_to_words(i) for i in testReviews]\n",
    "\n",
    "# vectorize the reviews using trained vectorizer2\n",
    "clean_test_reviews_feature = vectorizer2.transform(clean_test_reviews)\n",
    "clean_test_reviews_feature = clean_test_reviews_feature.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_predict = forest.predict(clean_test_reviews_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.  5.  4.  5.  4.  4.  4.  5.  5.  4.  4.  4.  4.  4.  4.  4.  4.  4.\n",
      "  4.  4.  5.  4.  4.  4.  4.  4.  5.  5.  4.  3.  4.  5.  4.  3.  4.  4.\n",
      "  4.  4.  5.  4.  5.  4.  4.  5.  5.  4.  4.  5.  4.  4.  4.  5.  4.  4.\n",
      "  4.  4.  4.  4.  4.  5.  4.  4.  4.  4.  4.  5.  3.  5.  5.  4.  5.  4.\n",
      "  5.  5.  5.  4.  3.  5.  5.  4.  4.  4.  5.  5.  5.  5.  5.  4.  4.  4.\n",
      "  4.  4.  4.  5.  4.  4.  4.  4.  5.  5.]\n"
     ]
    }
   ],
   "source": [
    "print(test_predict[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:    0.589671564391\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(testScore, test_predict)\n",
    "print(\"accuracy:   \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
