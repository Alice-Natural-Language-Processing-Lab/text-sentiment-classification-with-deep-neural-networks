{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using Barcelona hotel review data and as to (5-folder sentiment analysis classifier) to train lstm classifier\n",
    "import tensorflow as tf\n",
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from keras.layers import LSTM\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getCollection(collName = \"\"):\n",
    "    '''\n",
    "    return pandas dataframe.\n",
    "    '''\n",
    "    cursor = db[collName].find({})\n",
    "    df = pd.DataFrame(list(cursor))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# connect to mongoclient and fetch Barcelona tripadvisor\n",
    "client = MongoClient()\n",
    "db = client.sentimentAnalysis\n",
    "BarcelonaTripDF = getCollection(\"barcelonaTripadvisor\")\n",
    "\n",
    "# using hotel reviews in amsterdam as test reviews\n",
    "amsterdamTrip = getCollection(\"amsterdamTripadvisor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negtive:  1.0\n",
      "group len:  113\n",
      "negtive:  2.0\n",
      "group len:  137\n",
      "postive:  4.0\n",
      "group len:  809\n",
      "postive:  5.0\n",
      "group len:  1674\n"
     ]
    }
   ],
   "source": [
    "negReviews = list()\n",
    "posReviews = list()\n",
    "\n",
    "for key, group in BarcelonaTripDF.groupby(\"score\"):\n",
    "    if key in [0, 1, 2]:\n",
    "        print(\"negtive: \", key)\n",
    "        print(\"group len: \", len(group))\n",
    "        negReviews += [i.split() for i in group[\"review\"]]\n",
    "    elif key in [4, 5]:\n",
    "        print(\"postive: \", key)\n",
    "        print(\"group len: \", len(group))\n",
    "        posReviews += [i.split() for i in group[\"review\"]]\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negtive:  1.0\n",
      "group len:  87\n",
      "negtive:  2.0\n",
      "group len:  85\n",
      "postive:  4.0\n",
      "group len:  728\n",
      "postive:  5.0\n",
      "group len:  1340\n"
     ]
    }
   ],
   "source": [
    "testNegReviews = list()\n",
    "testPosReviews = list()\n",
    "\n",
    "for key, group in amsterdamTrip.groupby(\"score\"):\n",
    "    if key in [0, 1, 2]:\n",
    "        print(\"negtive: \", key)\n",
    "        print(\"group len: \", len(group))\n",
    "        testNegReviews += [i.split() for i in group[\"review\"]]\n",
    "    elif key in [4, 5]:\n",
    "        print(\"postive: \", key)\n",
    "        print(\"group len: \", len(group))\n",
    "        testPosReviews += [i.split() for i in group[\"review\"]]\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2483"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(posReviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(negReviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2068"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testPosReviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testNegReviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LabeledSentence\n",
    "pos_docs = list()\n",
    "neg_docs = list()\n",
    "\n",
    "\n",
    "for i in range(len(posReviews)):\n",
    "    pos_docs.append(TaggedDocument(words=posReviews[i], tags=['TRAIN_POS_'+str(i)]))\n",
    "for i in range(len(negReviews)):\n",
    "    neg_docs.append(TaggedDocument(words=negReviews[i], tags=['TRAIN_NEG_'+str(i)]))    \n",
    "\n",
    "for i in range(len(testPosReviews)):\n",
    "    pos_docs.append(TaggedDocument(words=posReviews[i], tags=['TEST_POS_'+str(i)]))\n",
    "for i in range(len(testNegReviews)):\n",
    "    neg_docs.append(TaggedDocument(words=testNegReviews[i], tags=['TEST_NEG_'+str(i)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yi/anaconda3/lib/python3.5/site-packages/gensim/models/doc2vec.py:366: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
     ]
    }
   ],
   "source": [
    "# train doc2vec classifier\n",
    "model = gensim.models.Doc2Vec(neg_docs+pos_docs, min_count=1, window=10, size=100,\n",
    "                              sample=1e-4, negative=5, workers=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"./Reviews.d2v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Doc2Vec.load('./Reviews.d2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yi/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    model.train(neg_docs+pos_docs, total_examples=model.corpus_count, epochs=model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 2733\n",
    "\n",
    "train_arrays = numpy.zeros((2733, 100))\n",
    "train_labels = numpy.zeros(2733)\n",
    "\n",
    "for i in range(2483):\n",
    "    prefix_train_pos = \"TRAIN_POS_\" + str(i)\n",
    "    train_arrays[i] = model[prefix_train_pos]\n",
    "    train_labels[i] = 1\n",
    "for i in range(250):\n",
    "    prefix_train_neg = 'TRAIN_NEG_' + str(i)\n",
    "    train_arrays[2483 + i] = model[prefix_train_neg]\n",
    "    train_labels[2483 + i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for test hotel reviews dataset\n",
    "TEST_SIZE = 2240\n",
    "\n",
    "test_arrays = numpy.zeros((TEST_SIZE, 100))\n",
    "test_labels = numpy.zeros(TEST_SIZE)\n",
    "\n",
    "for i in range(2068):\n",
    "    prefix_train_pos = \"TEST_POS_\" + str(i)\n",
    "    test_arrays[i] = model[prefix_train_pos]\n",
    "    test_labels[i] = 1\n",
    "for i in range(172):\n",
    "    prefix_train_neg = 'TEST_NEG_' + str(i)\n",
    "    test_arrays[2068 + i] = model[prefix_train_neg]\n",
    "    test_labels[2068 + i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# using logistic regression as classifier \n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(train_arrays, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9267857142857143"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(test_arrays, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using svm as classifier\n",
    "from sklearn import svm\n",
    "svmClf = svm.SVC()\n",
    "svmClf.fit(train_arrays, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.934375"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svmClf.score(test_arrays, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using keras to implement lstm sentiment analysis\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.core import Dense, Dropout,Activation\n",
    "from keras.models import model_from_yaml\n",
    "import multiprocessing\n",
    "\n",
    "# set parameters:\n",
    "vocab_dim = 100\n",
    "maxlen = 100\n",
    "n_iterations = 1  # ideally more..\n",
    "n_exposures = 10\n",
    "window_size = 7\n",
    "batch_size = 32\n",
    "n_epoch = 4\n",
    "input_length = 100\n",
    "cpu_count = multiprocessing.cpu_count()\n",
    "\n",
    "\n",
    "# below start apply lstm(long short term memory neural network)\n",
    "##定义网络结构\n",
    "def train_lstm(n_symbols,embedding_weights,x_train,y_train,x_test,y_test):\n",
    "    print('Defining a Simple Keras Model...')\n",
    "    model = Sequential()  # or Graph or whatever\n",
    "    model.add(Embedding(output_dim=vocab_dim,\n",
    "                        input_dim=n_symbols,\n",
    "                        mask_zero=True,\n",
    "                        weights=[embedding_weights],\n",
    "                        input_length=input_length))  # Adding Input Length\n",
    "    model.add(LSTM(output_dim=50, activation='sigmoid', inner_activation='hard_sigmoid'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    print('Compiling the Model...')\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "    print(\"Train...\")\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, \n",
    "              nb_epoch=n_epoch,verbose=1, validation_data=(x_test, y_test),show_accuracy=True)\n",
    "\n",
    "    print(\"Evaluate...\")\n",
    "    score = model.evaluate(x_test, y_test,\n",
    "                                batch_size=batch_size)\n",
    "\n",
    "    yaml_string = model.to_yaml()\n",
    "    with open('lstm_data/lstm.yml', 'w') as outfile:\n",
    "        outfile.write( yaml.dump(yaml_string, default_flow_style=True) )\n",
    "    model.save_weights('lstm_data/lstm.h5')\n",
    "    print('Test score:', score)\n",
    "    \n",
    "    \n",
    "    \n",
    "def lstm_predict(string):\n",
    "    print('loading model......')\n",
    "    with open('lstm_data/lstm.yml', 'r') as f:\n",
    "        yaml_string = yaml.load(f)\n",
    "    model = model_from_yaml(yaml_string)\n",
    "\n",
    "    print('loading weights......')\n",
    "    model.load_weights('lstm_data/lstm.h5')\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',metrics=['accuracy'])\n",
    "    data=input_transform(string)\n",
    "    data.reshape(1,-1)\n",
    "    #print data\n",
    "    result=model.predict_classes(data)\n",
    "    if result[0][0]==1:\n",
    "        print(string,' positive')\n",
    "    else:\n",
    "        print(string,' negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using tensorflow to implement LSTM sentiment analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if score <= 2 then, the review is considered as negative, if socre >= 4, then we say these reviews are positive\n",
    "model = gensim.models.Word2Vec(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('./BarcelonaGensimWord2Vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelBarcelona = gensim.models.Word2Vec.load(\"./BarcelonaGensimWord2Vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(modelBarcelona.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method keys of dict object at 0x7f865996e048>\n"
     ]
    }
   ],
   "source": [
    "print(modelBarcelona.wv.vocab.keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Camper': <gensim.models.keyedvectors.Vocab at 0x7f8663baa0b8>,\n",
       " 'Casa': <gensim.models.keyedvectors.Vocab at 0x7f8663ba6e48>,\n",
       " 'I': <gensim.models.keyedvectors.Vocab at 0x7f8663ba6be0>,\n",
       " 'The': <gensim.models.keyedvectors.Vocab at 0x7f8663ba6b38>,\n",
       " 'We': <gensim.models.keyedvectors.Vocab at 0x7f8663ba69e8>,\n",
       " 'a': <gensim.models.keyedvectors.Vocab at 0x7f8663ba6ac8>,\n",
       " 'all': <gensim.models.keyedvectors.Vocab at 0x7f8663ba6cf8>,\n",
       " 'and': <gensim.models.keyedvectors.Vocab at 0x7f8663ba6d30>,\n",
       " 'are': <gensim.models.keyedvectors.Vocab at 0x7f8663ba6978>,\n",
       " 'as': <gensim.models.keyedvectors.Vocab at 0x7f8663baa048>,\n",
       " 'but': <gensim.models.keyedvectors.Vocab at 0x7f8663ba6ef0>,\n",
       " 'for': <gensim.models.keyedvectors.Vocab at 0x7f8663ba6b00>,\n",
       " 'had': <gensim.models.keyedvectors.Vocab at 0x7f8663ba6f60>,\n",
       " 'have': <gensim.models.keyedvectors.Vocab at 0x7f8663ba6dd8>,\n",
       " 'hotel': <gensim.models.keyedvectors.Vocab at 0x7f8663baa278>,\n",
       " 'in': <gensim.models.keyedvectors.Vocab at 0x7f8663baa128>,\n",
       " 'is': <gensim.models.keyedvectors.Vocab at 0x7f8663baa208>,\n",
       " 'it': <gensim.models.keyedvectors.Vocab at 0x7f8663ba6ba8>,\n",
       " 'my': <gensim.models.keyedvectors.Vocab at 0x7f8663baa0f0>,\n",
       " 'of': <gensim.models.keyedvectors.Vocab at 0x7f8663ba6908>,\n",
       " 'only': <gensim.models.keyedvectors.Vocab at 0x7f8663ba6e10>,\n",
       " 'our': <gensim.models.keyedvectors.Vocab at 0x7f8663ba6940>,\n",
       " 'room': <gensim.models.keyedvectors.Vocab at 0x7f8663ba6c18>,\n",
       " 'so': <gensim.models.keyedvectors.Vocab at 0x7f8663ba6e80>,\n",
       " 'staff': <gensim.models.keyedvectors.Vocab at 0x7f8663ba6eb8>,\n",
       " 'stay': <gensim.models.keyedvectors.Vocab at 0x7f8663ba68d0>,\n",
       " 'that': <gensim.models.keyedvectors.Vocab at 0x7f8663ba6c88>,\n",
       " 'the': <gensim.models.keyedvectors.Vocab at 0x7f8663ba6f98>,\n",
       " 'there': <gensim.models.keyedvectors.Vocab at 0x7f8663ba67b8>,\n",
       " 'this': <gensim.models.keyedvectors.Vocab at 0x7f8663ba6a58>,\n",
       " 'to': <gensim.models.keyedvectors.Vocab at 0x7f8663ba6a90>,\n",
       " 'very': <gensim.models.keyedvectors.Vocab at 0x7f8663ba6828>,\n",
       " 'was': <gensim.models.keyedvectors.Vocab at 0x7f8663ba6860>,\n",
       " 'we': <gensim.models.keyedvectors.Vocab at 0x7f8663ba6898>,\n",
       " 'were': <gensim.models.keyedvectors.Vocab at 0x7f8663ba6da0>,\n",
       " 'which': <gensim.models.keyedvectors.Vocab at 0x7f8663ba6a20>,\n",
       " 'with': <gensim.models.keyedvectors.Vocab at 0x7f8663ba6cc0>,\n",
       " 'you': <gensim.models.keyedvectors.Vocab at 0x7f8663ba6fd0>}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yi/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-2.7176237e-03, -4.2124532e-04, -2.9958170e-03,  1.7631396e-03,\n",
       "        1.6334026e-04, -2.3682714e-03,  5.2180332e-03, -6.6152535e-04,\n",
       "       -3.6912810e-03,  1.7486790e-03,  2.4528317e-03, -4.9182242e-03,\n",
       "        4.6032267e-03, -2.8638407e-03,  1.1333899e-03,  1.3599114e-03,\n",
       "       -3.5398798e-03,  3.2488762e-03,  5.4170075e-03,  3.7243727e-03,\n",
       "       -4.4740876e-03,  2.2812365e-03,  3.8590247e-03,  3.4430004e-03,\n",
       "       -5.7903898e-04, -2.9486124e-03, -2.0798463e-03, -2.6243101e-03,\n",
       "        9.5090445e-04,  7.0516166e-04, -3.9693285e-03,  4.6384539e-03,\n",
       "       -8.3733542e-04,  1.0782755e-04,  3.6009306e-03, -2.3609167e-03,\n",
       "       -1.0568458e-03,  4.7210283e-03,  2.3235232e-03, -8.5816864e-04,\n",
       "       -2.6506307e-03, -4.4114804e-03,  2.9152636e-03, -2.0264154e-03,\n",
       "       -7.8529329e-04, -5.0564236e-03,  2.0137927e-03, -4.8121922e-03,\n",
       "       -4.5178170e-04, -2.4561922e-03, -4.4617970e-03, -5.3392071e-03,\n",
       "        4.2272461e-04, -2.7396725e-03, -9.6188608e-04,  9.8271517e-04,\n",
       "        1.8208358e-03,  4.6293340e-03, -1.2186872e-03,  1.3370853e-05,\n",
       "       -2.3562254e-03,  3.1378067e-03,  1.9190639e-03,  4.0099220e-03,\n",
       "        4.1009686e-03,  1.6364638e-03,  3.6326269e-04,  2.5119318e-03,\n",
       "        4.4377693e-03,  4.5108108e-04,  4.7841468e-03,  4.7804229e-03,\n",
       "       -1.1685652e-03,  2.5246155e-03, -3.3536600e-03, -1.3372684e-03,\n",
       "       -2.2432746e-03, -1.4490029e-03, -4.7067539e-03, -4.8298561e-03,\n",
       "        3.2339026e-03,  4.9988413e-03,  1.0008077e-04,  2.8800615e-03,\n",
       "       -7.8215665e-04, -3.5078793e-03, -1.3753729e-03, -4.3508075e-03,\n",
       "       -3.8293243e-04, -8.4353954e-04,  1.4011819e-03,  3.4910212e-03,\n",
       "        5.9548119e-04, -2.9577829e-03,  4.7348682e-03,  5.1230243e-03,\n",
       "       -6.1280828e-04, -7.6022506e-04, -1.0953404e-03, -1.5892265e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[\"you\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'woman' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-719407187db9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"woman\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"king\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"man\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    363\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'woman' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "model.wv.most_similar(positive=[\"\", \"king\"], negative=\"man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!': <gensim.models.keyedvectors.Vocab at 0x7f8663bf5d68>,\n",
       " \"'\": <gensim.models.keyedvectors.Vocab at 0x7f8663c002e8>,\n",
       " ',': <gensim.models.keyedvectors.Vocab at 0x7f8663bfb198>,\n",
       " '-': <gensim.models.keyedvectors.Vocab at 0x7f8663c04080>,\n",
       " '.': <gensim.models.keyedvectors.Vocab at 0x7f8663c00518>,\n",
       " 'A': <gensim.models.keyedvectors.Vocab at 0x7f8663c006a0>,\n",
       " 'B': <gensim.models.keyedvectors.Vocab at 0x7f8663c04f60>,\n",
       " 'C': <gensim.models.keyedvectors.Vocab at 0x7f8663bfb278>,\n",
       " 'E': <gensim.models.keyedvectors.Vocab at 0x7f8663bfb780>,\n",
       " 'F': <gensim.models.keyedvectors.Vocab at 0x7f8663c00550>,\n",
       " 'G': <gensim.models.keyedvectors.Vocab at 0x7f8663bfb3c8>,\n",
       " 'I': <gensim.models.keyedvectors.Vocab at 0x7f8663c00f60>,\n",
       " 'L': <gensim.models.keyedvectors.Vocab at 0x7f8663c040f0>,\n",
       " 'N': <gensim.models.keyedvectors.Vocab at 0x7f8663c00eb8>,\n",
       " 'O': <gensim.models.keyedvectors.Vocab at 0x7f8663c00c50>,\n",
       " 'R': <gensim.models.keyedvectors.Vocab at 0x7f8663c04fd0>,\n",
       " 'S': <gensim.models.keyedvectors.Vocab at 0x7f8663c007b8>,\n",
       " 'T': <gensim.models.keyedvectors.Vocab at 0x7f8663c00780>,\n",
       " 'U': <gensim.models.keyedvectors.Vocab at 0x7f8663c04128>,\n",
       " 'V': <gensim.models.keyedvectors.Vocab at 0x7f8663c00f28>,\n",
       " 'W': <gensim.models.keyedvectors.Vocab at 0x7f8663c008d0>,\n",
       " 'Y': <gensim.models.keyedvectors.Vocab at 0x7f8663c00630>,\n",
       " 'a': <gensim.models.keyedvectors.Vocab at 0x7f8663bf5cf8>,\n",
       " 'b': <gensim.models.keyedvectors.Vocab at 0x7f8663c00898>,\n",
       " 'c': <gensim.models.keyedvectors.Vocab at 0x7f8663c009b0>,\n",
       " 'd': <gensim.models.keyedvectors.Vocab at 0x7f8663bfb9e8>,\n",
       " 'e': <gensim.models.keyedvectors.Vocab at 0x7f8663c00400>,\n",
       " 'f': <gensim.models.keyedvectors.Vocab at 0x7f8663c00278>,\n",
       " 'g': <gensim.models.keyedvectors.Vocab at 0x7f8663bf5e48>,\n",
       " 'h': <gensim.models.keyedvectors.Vocab at 0x7f8663c00c88>,\n",
       " 'i': <gensim.models.keyedvectors.Vocab at 0x7f8663bfb8d0>,\n",
       " 'j': <gensim.models.keyedvectors.Vocab at 0x7f8663c00a20>,\n",
       " 'k': <gensim.models.keyedvectors.Vocab at 0x7f8663bfb2b0>,\n",
       " 'l': <gensim.models.keyedvectors.Vocab at 0x7f8663bf5f28>,\n",
       " 'm': <gensim.models.keyedvectors.Vocab at 0x7f8663c00b70>,\n",
       " 'n': <gensim.models.keyedvectors.Vocab at 0x7f8663bfb668>,\n",
       " 'o': <gensim.models.keyedvectors.Vocab at 0x7f8663bfb4e0>,\n",
       " 'p': <gensim.models.keyedvectors.Vocab at 0x7f8663c00da0>,\n",
       " 'r': <gensim.models.keyedvectors.Vocab at 0x7f8663bfb978>,\n",
       " 's': <gensim.models.keyedvectors.Vocab at 0x7f8663c00748>,\n",
       " 't': <gensim.models.keyedvectors.Vocab at 0x7f8663c00438>,\n",
       " 'u': <gensim.models.keyedvectors.Vocab at 0x7f8663c00b00>,\n",
       " 'v': <gensim.models.keyedvectors.Vocab at 0x7f8663c003c8>,\n",
       " 'w': <gensim.models.keyedvectors.Vocab at 0x7f8663c00e10>,\n",
       " 'y': <gensim.models.keyedvectors.Vocab at 0x7f8663c00b38>}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yi/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.0652876 , -0.02379496,  0.28427863,  0.22806762, -0.0402721 ,\n",
       "        0.22190231, -0.28464034,  0.1134514 ,  0.01343165, -0.35749656,\n",
       "        0.0014141 , -0.24401037,  0.14565443,  0.22039108, -0.06951722,\n",
       "        0.00307713,  0.12986048,  0.12285537, -0.02502411,  0.1432696 ,\n",
       "        0.09000761,  0.07506921, -0.10763656, -0.08317614,  0.03427026,\n",
       "        0.16992094, -0.08538722,  0.12460461, -0.02682418, -0.00146557,\n",
       "       -0.0702408 , -0.07357073, -0.29178527,  0.13437575, -0.0272955 ,\n",
       "       -0.01592053,  0.02521549,  0.2799897 ,  0.0790484 , -0.00777822,\n",
       "       -0.01319677, -0.1299203 , -0.2593838 , -0.16250567, -0.08295222,\n",
       "       -0.13591553,  0.16659208,  0.17449483,  0.19507363, -0.0390104 ,\n",
       "       -0.01474262, -0.05659554,  0.00456479,  0.01641093,  0.07135551,\n",
       "       -0.0871382 , -0.05405086, -0.16807927,  0.00228584,  0.01154468,\n",
       "        0.09966996,  0.08097436,  0.17029196,  0.01451492,  0.0965705 ,\n",
       "       -0.03664728, -0.03110873, -0.1515383 ,  0.09444817,  0.01663193,\n",
       "       -0.04251469,  0.07674687,  0.21944472,  0.01698565, -0.1905871 ,\n",
       "        0.13598362,  0.01399085, -0.11882447,  0.00080514,  0.17295326,\n",
       "       -0.03130788, -0.00472026,  0.06140513, -0.10579476,  0.12964594,\n",
       "        0.08818304,  0.12713706, -0.22936623, -0.13200551,  0.12589586,\n",
       "       -0.19387847, -0.19222635,  0.03858528,  0.01613943, -0.07481217,\n",
       "        0.12818414, -0.12823115,  0.02276706, -0.06279127,  0.01984107],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[\"X\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': <gensim.models.keyedvectors.Vocab at 0x7f8663c759b0>,\n",
       " '!': <gensim.models.keyedvectors.Vocab at 0x7f8663c83a58>,\n",
       " '\"': <gensim.models.keyedvectors.Vocab at 0x7f8663c72a58>,\n",
       " '#': <gensim.models.keyedvectors.Vocab at 0x7f8663c83f98>,\n",
       " '$': <gensim.models.keyedvectors.Vocab at 0x7f8663c7c3c8>,\n",
       " '%': <gensim.models.keyedvectors.Vocab at 0x7f8663c83550>,\n",
       " '&': <gensim.models.keyedvectors.Vocab at 0x7f8663c79390>,\n",
       " \"'\": <gensim.models.keyedvectors.Vocab at 0x7f8663c79128>,\n",
       " '(': <gensim.models.keyedvectors.Vocab at 0x7f8663c7cda0>,\n",
       " ')': <gensim.models.keyedvectors.Vocab at 0x7f8663c72080>,\n",
       " '*': <gensim.models.keyedvectors.Vocab at 0x7f8663c7c320>,\n",
       " '+': <gensim.models.keyedvectors.Vocab at 0x7f8663c83cf8>,\n",
       " ',': <gensim.models.keyedvectors.Vocab at 0x7f8663c75d30>,\n",
       " '-': <gensim.models.keyedvectors.Vocab at 0x7f8663c72b00>,\n",
       " '.': <gensim.models.keyedvectors.Vocab at 0x7f8663c7c860>,\n",
       " '/': <gensim.models.keyedvectors.Vocab at 0x7f8663c79898>,\n",
       " '0': <gensim.models.keyedvectors.Vocab at 0x7f8663c75240>,\n",
       " '1': <gensim.models.keyedvectors.Vocab at 0x7f8663c7c080>,\n",
       " '2': <gensim.models.keyedvectors.Vocab at 0x7f8663c750f0>,\n",
       " '3': <gensim.models.keyedvectors.Vocab at 0x7f8663c830f0>,\n",
       " '4': <gensim.models.keyedvectors.Vocab at 0x7f8663c8ce48>,\n",
       " '5': <gensim.models.keyedvectors.Vocab at 0x7f8663c7c5f8>,\n",
       " '6': <gensim.models.keyedvectors.Vocab at 0x7f8663c75898>,\n",
       " '7': <gensim.models.keyedvectors.Vocab at 0x7f8663c79a90>,\n",
       " '8': <gensim.models.keyedvectors.Vocab at 0x7f8663c7f748>,\n",
       " '9': <gensim.models.keyedvectors.Vocab at 0x7f8663c724e0>,\n",
       " ':': <gensim.models.keyedvectors.Vocab at 0x7f8663c72748>,\n",
       " ';': <gensim.models.keyedvectors.Vocab at 0x7f8663c72390>,\n",
       " '<': <gensim.models.keyedvectors.Vocab at 0x7f8663c7c048>,\n",
       " '=': <gensim.models.keyedvectors.Vocab at 0x7f8663c7c9b0>,\n",
       " '?': <gensim.models.keyedvectors.Vocab at 0x7f8663c79828>,\n",
       " '@': <gensim.models.keyedvectors.Vocab at 0x7f8663c75390>,\n",
       " 'A': <gensim.models.keyedvectors.Vocab at 0x7f8663c72a90>,\n",
       " 'B': <gensim.models.keyedvectors.Vocab at 0x7f8663c7c160>,\n",
       " 'C': <gensim.models.keyedvectors.Vocab at 0x7f8663c79668>,\n",
       " 'D': <gensim.models.keyedvectors.Vocab at 0x7f8663c75198>,\n",
       " 'E': <gensim.models.keyedvectors.Vocab at 0x7f8663c72e48>,\n",
       " 'F': <gensim.models.keyedvectors.Vocab at 0x7f8663c79e48>,\n",
       " 'G': <gensim.models.keyedvectors.Vocab at 0x7f8663c72f28>,\n",
       " 'H': <gensim.models.keyedvectors.Vocab at 0x7f8663c79e10>,\n",
       " 'I': <gensim.models.keyedvectors.Vocab at 0x7f8663c83eb8>,\n",
       " 'J': <gensim.models.keyedvectors.Vocab at 0x7f8663c83080>,\n",
       " 'K': <gensim.models.keyedvectors.Vocab at 0x7f8663c72860>,\n",
       " 'L': <gensim.models.keyedvectors.Vocab at 0x7f8663c7c2b0>,\n",
       " 'M': <gensim.models.keyedvectors.Vocab at 0x7f8663c72eb8>,\n",
       " 'N': <gensim.models.keyedvectors.Vocab at 0x7f8663c79fd0>,\n",
       " 'O': <gensim.models.keyedvectors.Vocab at 0x7f8663c7c8d0>,\n",
       " 'P': <gensim.models.keyedvectors.Vocab at 0x7f8663c794a8>,\n",
       " 'Q': <gensim.models.keyedvectors.Vocab at 0x7f8663c83940>,\n",
       " 'R': <gensim.models.keyedvectors.Vocab at 0x7f8663c83828>,\n",
       " 'S': <gensim.models.keyedvectors.Vocab at 0x7f8663c75780>,\n",
       " 'T': <gensim.models.keyedvectors.Vocab at 0x7f8663c7c748>,\n",
       " 'U': <gensim.models.keyedvectors.Vocab at 0x7f8663c7c470>,\n",
       " 'V': <gensim.models.keyedvectors.Vocab at 0x7f8663c83cc0>,\n",
       " 'W': <gensim.models.keyedvectors.Vocab at 0x7f8663c75278>,\n",
       " 'X': <gensim.models.keyedvectors.Vocab at 0x7f8663c79400>,\n",
       " 'Y': <gensim.models.keyedvectors.Vocab at 0x7f8663c798d0>,\n",
       " 'Z': <gensim.models.keyedvectors.Vocab at 0x7f8663c7c550>,\n",
       " '[': <gensim.models.keyedvectors.Vocab at 0x7f8663c72048>,\n",
       " ']': <gensim.models.keyedvectors.Vocab at 0x7f8663c8ce80>,\n",
       " 'a': <gensim.models.keyedvectors.Vocab at 0x7f8663c79940>,\n",
       " 'b': <gensim.models.keyedvectors.Vocab at 0x7f8663c7cef0>,\n",
       " 'c': <gensim.models.keyedvectors.Vocab at 0x7f8663c72fd0>,\n",
       " 'd': <gensim.models.keyedvectors.Vocab at 0x7f8663c79c18>,\n",
       " 'e': <gensim.models.keyedvectors.Vocab at 0x7f8663c83438>,\n",
       " 'f': <gensim.models.keyedvectors.Vocab at 0x7f8663c75eb8>,\n",
       " 'g': <gensim.models.keyedvectors.Vocab at 0x7f8663c7c588>,\n",
       " 'h': <gensim.models.keyedvectors.Vocab at 0x7f8663c7cdd8>,\n",
       " 'i': <gensim.models.keyedvectors.Vocab at 0x7f8663c79710>,\n",
       " 'j': <gensim.models.keyedvectors.Vocab at 0x7f8663c723c8>,\n",
       " 'k': <gensim.models.keyedvectors.Vocab at 0x7f86680296d8>,\n",
       " 'l': <gensim.models.keyedvectors.Vocab at 0x7f8663c83048>,\n",
       " 'm': <gensim.models.keyedvectors.Vocab at 0x7f8663c79278>,\n",
       " 'n': <gensim.models.keyedvectors.Vocab at 0x7f8663c72128>,\n",
       " 'o': <gensim.models.keyedvectors.Vocab at 0x7f8663c754a8>,\n",
       " 'p': <gensim.models.keyedvectors.Vocab at 0x7f8663c79160>,\n",
       " 'q': <gensim.models.keyedvectors.Vocab at 0x7f8663c79cc0>,\n",
       " 'r': <gensim.models.keyedvectors.Vocab at 0x7f8663c79a20>,\n",
       " 's': <gensim.models.keyedvectors.Vocab at 0x7f8663c75b00>,\n",
       " 't': <gensim.models.keyedvectors.Vocab at 0x7f8663c836d8>,\n",
       " 'u': <gensim.models.keyedvectors.Vocab at 0x7f8663c725f8>,\n",
       " 'v': <gensim.models.keyedvectors.Vocab at 0x7f8663c835c0>,\n",
       " 'w': <gensim.models.keyedvectors.Vocab at 0x7f8663c7cf60>,\n",
       " 'x': <gensim.models.keyedvectors.Vocab at 0x7f8663c79c50>,\n",
       " 'y': <gensim.models.keyedvectors.Vocab at 0x7f8663c7c978>,\n",
       " 'z': <gensim.models.keyedvectors.Vocab at 0x7f8663c79860>,\n",
       " '~': <gensim.models.keyedvectors.Vocab at 0x7f8663c72278>,\n",
       " '\\xa0': <gensim.models.keyedvectors.Vocab at 0x7f8663c75668>,\n",
       " '£': <gensim.models.keyedvectors.Vocab at 0x7f8663c722e8>,\n",
       " '¨': <gensim.models.keyedvectors.Vocab at 0x7f8663c75748>,\n",
       " '°': <gensim.models.keyedvectors.Vocab at 0x7f8663c72668>,\n",
       " '´': <gensim.models.keyedvectors.Vocab at 0x7f8663c796d8>,\n",
       " 'à': <gensim.models.keyedvectors.Vocab at 0x7f8663c83e10>,\n",
       " 'á': <gensim.models.keyedvectors.Vocab at 0x7f8663c75b38>,\n",
       " 'å': <gensim.models.keyedvectors.Vocab at 0x7f8663c72160>,\n",
       " 'ç': <gensim.models.keyedvectors.Vocab at 0x7f8663c755f8>,\n",
       " 'è': <gensim.models.keyedvectors.Vocab at 0x7f8663c72d30>,\n",
       " 'é': <gensim.models.keyedvectors.Vocab at 0x7f8663c753c8>,\n",
       " 'ë': <gensim.models.keyedvectors.Vocab at 0x7f8663c79b70>,\n",
       " 'í': <gensim.models.keyedvectors.Vocab at 0x7f8663c7ceb8>,\n",
       " 'ï': <gensim.models.keyedvectors.Vocab at 0x7f8663c7cc50>,\n",
       " 'ñ': <gensim.models.keyedvectors.Vocab at 0x7f8663c721d0>,\n",
       " 'ò': <gensim.models.keyedvectors.Vocab at 0x7f8663c83d30>,\n",
       " 'ó': <gensim.models.keyedvectors.Vocab at 0x7f8663c72e10>,\n",
       " 'ô': <gensim.models.keyedvectors.Vocab at 0x7f8663c83908>,\n",
       " 'ø': <gensim.models.keyedvectors.Vocab at 0x7f8663c797b8>,\n",
       " 'ú': <gensim.models.keyedvectors.Vocab at 0x7f8663c75a20>,\n",
       " 'ü': <gensim.models.keyedvectors.Vocab at 0x7f8663c72518>,\n",
       " 'ć': <gensim.models.keyedvectors.Vocab at 0x7f8663c79eb8>,\n",
       " 'İ': <gensim.models.keyedvectors.Vocab at 0x7f8663c79ac8>,\n",
       " '–': <gensim.models.keyedvectors.Vocab at 0x7f8663c83b70>,\n",
       " '‘': <gensim.models.keyedvectors.Vocab at 0x7f8663c79f60>,\n",
       " '’': <gensim.models.keyedvectors.Vocab at 0x7f8663c759e8>,\n",
       " '“': <gensim.models.keyedvectors.Vocab at 0x7f8663c83fd0>,\n",
       " '”': <gensim.models.keyedvectors.Vocab at 0x7f8663c75c88>,\n",
       " '…': <gensim.models.keyedvectors.Vocab at 0x7f8663c7c438>,\n",
       " '€': <gensim.models.keyedvectors.Vocab at 0x7f8663c83978>,\n",
       " '❤': <gensim.models.keyedvectors.Vocab at 0x7f8663c72710>,\n",
       " '⭐': <gensim.models.keyedvectors.Vocab at 0x7f8663c75128>,\n",
       " '。': <gensim.models.keyedvectors.Vocab at 0x7f8663c72400>,\n",
       " '一': <gensim.models.keyedvectors.Vocab at 0x7f8663c7c198>,\n",
       " '个': <gensim.models.keyedvectors.Vocab at 0x7f8663c72ef0>,\n",
       " '位': <gensim.models.keyedvectors.Vocab at 0x7f8663c79048>,\n",
       " '光': <gensim.models.keyedvectors.Vocab at 0x7f8663c72240>,\n",
       " '到': <gensim.models.keyedvectors.Vocab at 0x7f8663c79518>,\n",
       " '在': <gensim.models.keyedvectors.Vocab at 0x7f8663c79d68>,\n",
       " '地': <gensim.models.keyedvectors.Vocab at 0x7f8663c75d68>,\n",
       " '基': <gensim.models.keyedvectors.Vocab at 0x7f8663c75c18>,\n",
       " '境': <gensim.models.keyedvectors.Vocab at 0x7f8663c7c7b8>,\n",
       " '大': <gensim.models.keyedvectors.Vocab at 0x7f8663c7c710>,\n",
       " '家': <gensim.models.keyedvectors.Vocab at 0x7f8663c796a0>,\n",
       " '床': <gensim.models.keyedvectors.Vocab at 0x7f8663c72b38>,\n",
       " '店': <gensim.models.keyedvectors.Vocab at 0x7f8663c7cb00>,\n",
       " '很': <gensim.models.keyedvectors.Vocab at 0x7f8663c83588>,\n",
       " '想': <gensim.models.keyedvectors.Vocab at 0x7f8663c72c18>,\n",
       " '我': <gensim.models.keyedvectors.Vocab at 0x7f8663c72898>,\n",
       " '房': <gensim.models.keyedvectors.Vocab at 0x7f8663c7cd30>,\n",
       " '旅': <gensim.models.keyedvectors.Vocab at 0x7f8663c79a58>,\n",
       " '日': <gensim.models.keyedvectors.Vocab at 0x7f8663c7f828>,\n",
       " '是': <gensim.models.keyedvectors.Vocab at 0x7f8663c75da0>,\n",
       " '最': <gensim.models.keyedvectors.Vocab at 0x7f8663c834a8>,\n",
       " '服': <gensim.models.keyedvectors.Vocab at 0x7f8663c79ba8>,\n",
       " '本': <gensim.models.keyedvectors.Vocab at 0x7f8663c79198>,\n",
       " '没': <gensim.models.keyedvectors.Vocab at 0x7f8663c75048>,\n",
       " '流': <gensim.models.keyedvectors.Vocab at 0x7f8663c72358>,\n",
       " '浴': <gensim.models.keyedvectors.Vocab at 0x7f8663c7cac8>,\n",
       " '牙': <gensim.models.keyedvectors.Vocab at 0x7f8663c797f0>,\n",
       " '环': <gensim.models.keyedvectors.Vocab at 0x7f8663c75208>,\n",
       " '班': <gensim.models.keyedvectors.Vocab at 0x7f8663c792b0>,\n",
       " '的': <gensim.models.keyedvectors.Vocab at 0x7f8663c79f28>,\n",
       " '置': <gensim.models.keyedvectors.Vocab at 0x7f8663c72208>,\n",
       " '舒': <gensim.models.keyedvectors.Vocab at 0x7f8663c75908>,\n",
       " '西': <gensim.models.keyedvectors.Vocab at 0x7f8663c720f0>,\n",
       " '費': <gensim.models.keyedvectors.Vocab at 0x7f8663c7c9e8>,\n",
       " '这': <gensim.models.keyedvectors.Vocab at 0x7f8663c72c88>,\n",
       " '這': <gensim.models.keyedvectors.Vocab at 0x7f8663c752b0>,\n",
       " '酒': <gensim.models.keyedvectors.Vocab at 0x7f8663c83a90>,\n",
       " '间': <gensim.models.keyedvectors.Vocab at 0x7f8663c72780>,\n",
       " '️': <gensim.models.keyedvectors.Vocab at 0x7f8663c72320>,\n",
       " '，': <gensim.models.keyedvectors.Vocab at 0x7f8663c7cbe0>,\n",
       " '？': <gensim.models.keyedvectors.Vocab at 0x7f8663c72be0>}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Word2Vec.accuracy of <gensim.models.word2vec.Word2Vec object at 0x7f8663c75f28>>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseWordEmbeddingsModel.estimate_memory of <gensim.models.word2vec.Word2Vec object at 0x7f8663c75f28>>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimate_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'location' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a0b2844fd874>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"location\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, entities)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'location' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "model.wv[\"location\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vocabulary.sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yi/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"word 'say' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-ace34c71ac26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msay_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'say'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mnew_func1\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1396\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m                 )\n\u001b[0;32m-> 1398\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_func1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, words)\u001b[0m\n\u001b[1;32m    819\u001b[0m         \u001b[0mRefer\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocumentation\u001b[0m \u001b[0;32mfor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeyedvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWord2VecKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \"\"\"\n\u001b[0;32m--> 821\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Method will be removed in 4.0.0, use self.wv.__contains__() instead\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, entities)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'say' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "say_vector = model['say']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#对每个句子的所有词向量取均值\n",
    "def buildWordVector(text, size,imdb_w2v):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0.\n",
    "    for word in text:\n",
    "        try:\n",
    "            vec += imdb_w2v[word].reshape((1, size))\n",
    "            count += 1.\n",
    "        except KeyError:\n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print' (<ipython-input-18-410d0a97d5fc>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-410d0a97d5fc>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    print train_vecs.shape\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'\n"
     ]
    }
   ],
   "source": [
    "#计算词向量\n",
    "def get_train_vecs(x_train,x_test):\n",
    "    n_dim = 300\n",
    "    #Initialize model and build vocab\n",
    "    imdb_w2v = Word2Vec(size=n_dim, min_count=10)\n",
    "    imdb_w2v.build_vocab(x_train)\n",
    "\n",
    "    #Train the model over train_reviews (this may take several minutes)\n",
    "    imdb_w2v.train(x_train)\n",
    "\n",
    "    train_vecs = np.concatenate([buildWordVector(z, n_dim,imdb_w2v) for z in x_train])\n",
    "    #train_vecs = scale(train_vecs)\n",
    "\n",
    "    np.save('svm_data/train_vecs.npy',train_vecs)\n",
    "    print train_vecs.shape\n",
    "    #Train word2vec on test tweets\n",
    "    imdb_w2v.train(x_test)\n",
    "    imdb_w2v.save('svm_data/w2v_model/w2v_model.pkl')\n",
    "    #Build test tweet vectors then scale\n",
    "    test_vecs = np.concatenate([buildWordVector(z, n_dim,imdb_w2v) for z in x_test])\n",
    "    #test_vecs = scale(test_vecs)\n",
    "    np.save('svm_data/test_vecs.npy',test_vecs)\n",
    "    print(test_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model Hyperparameters\n",
    "\n",
    "sequence_length = 50\n",
    "embedding_dim = 300        \n",
    "filter_sizes = (3, 4)\n",
    "num_filters = 50\n",
    "dropout_prob = (0.25, 0.5)\n",
    "hidden_dims = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-15-92f31af118d9>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-92f31af118d9>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    model.add(Dropout(dropout_prob[0], input_shape=(sequence_length, embedding_dim)\u001b[0m\n\u001b[0m                                                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dropout(dropout_prob[0], input_shape=(sequence_length, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Recurrent Neural Network (RNN) using the Long Short Term Memory (LSTM) to calculate sentiment score on Barcelona\n",
    "# hotel reviews\n",
    "def lstm_sent(data):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
