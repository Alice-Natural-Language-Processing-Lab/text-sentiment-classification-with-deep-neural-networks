========================================================================================
cm = metrics.confusion_matrix(ground_truth, pred_result)
print(cm)
[[  83   36   20   10    3]
 [  57  115   91   13    5]
 [  33  126  382  251   43]
 [  11   17  263 1533  897]
 [   8    9   82 1307 4605]]



=========================================================================================
report = metrics.classification_report(ground_truth, pred_result, target_names=None)

print(report)
             precision    recall  f1-score   support

          0       0.43      0.55      0.48       152
          1       0.38      0.41      0.39       281
          2       0.46      0.46      0.46       835
          3       0.49      0.56      0.53      2721
          4       0.83      0.77      0.80      6011

avg / total       0.69      0.67      0.68     10000