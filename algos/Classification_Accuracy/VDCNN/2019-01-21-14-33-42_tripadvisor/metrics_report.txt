==================================================================================
cm = metrics.confusion_matrix(ground_truth, pred_result)

print(cm)
[[  82   39   23    4    4]
 [  50  109   87   28    7]
 [  30  125  385  254   41]
 [   9   23  297 1493  899]
 [   7    9   86 1403 4506]]


=================================================================================
report = metrics.classification_report(ground_truth, pred_result, target_names=None)

print(report)

             precision    recall  f1-score   support

          0       0.46      0.54      0.50       152
          1       0.36      0.39      0.37       281
          2       0.44      0.46      0.45       835
          3       0.47      0.55      0.51      2721
          4       0.83      0.75      0.79      6011

avg / total       0.68      0.66      0.67     10000