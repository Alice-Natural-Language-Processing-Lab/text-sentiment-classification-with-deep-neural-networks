{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import datetime\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Sentiment Calculation For reviews in Tripadvisor\").config(\n",
    "    \"spark.some.config.option\", \"sentiment\").getOrCreate()\n",
    "\n",
    "# input file name, city Oslo from tripadvisor as a demo\n",
    "inputfileName = \"reviewData/014_Oslo_tripadvisor.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputfileStatisticsName = \"reviewData/014_statistics_Oslo_Tripadvisor.json\"\n",
    "data = spark.read.json(inputfileName)\n",
    "dataStatistics = spark.read.json(inputfileStatisticsName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28154"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1st step, filter dirty data, including incomplete record, like absencing score, url.\n",
    "data = data.filter(\"review is not NULL\").filter(\"score is not NULL\").filter(\"url is not NULL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27988"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dateData = data.filter(\"date is not NULL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "534"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dateData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2 step. split the whole data into two parts, train data 80% and test data 20%\n",
    "train, test = data.randomSplit([0.8, 0.2], seed = 12345)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get only reviews and corresponding scores.\n",
    "trainLabels = list()\n",
    "trainReviews = list()\n",
    "\n",
    "trainReviews = train.select(\"review\").rdd.map(lambda x : x.review).collect()\n",
    "trainLabels = train.select(\"score\").rdd.map(lambda x : x.score).collect()\n",
    "\n",
    "testLabels = list()\n",
    "testReviews = list()\n",
    "\n",
    "testReviews = test.select(\"review\").rdd.map(lambda x : x.review).collect()\n",
    "testLabels = test.select(\"score\").rdd.map(lambda x : x.score).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviews and its label has the SAME length in both train and test dataset\n",
      "train data size:  22307 ; test data size:  5681\n"
     ]
    }
   ],
   "source": [
    "if len(trainReviews) == len(trainLabels) and len(testReviews) == len(testLabels):\n",
    "    print(\"reviews and its label has the SAME length in both train and test dataset\")\n",
    "    print(\"train data size: \", len(trainLabels), \"; test data size: \", len(testLabels))\n",
    "else:\n",
    "    print(\"reviews and labels don't have the same length, ERROR\")\n",
    "    print(\"train reviews length: \", len(trainReviews), \"; train labels length: \", len(trainLabels))\n",
    "    print(\"test reviews length: \", len(testReviews), \"; test labels length: \", len(testLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train a svm classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first method: 基于情感词典的文本情感极性分析\n",
    "# second method: 基于机器学习的文本情感极性分析\n",
    "# third method: 基于神经网络的文本情感分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# senti_wordnet class, using senti_wordnet 3.0 \n",
    "fswn = open(#open sentiment wordnet 3.0 file\n",
    "            \"/home/yi/Music/Sentiment-Analysis/SentiWordNet_3.0/swn/www/admin/dump/SentiWordNet_3.0.0_20130122.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "swn_lines = list()\n",
    "for line in fswn.readlines():\n",
    "    if line.startswith(\"#\"):\n",
    "        pass\n",
    "    else:\n",
    "        swn_lines.append(line.strip())\n",
    "fswn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a\\t00001740\\t0.125\\t0\\table#1\\t(usually followed by `to\\') having the necessary means or skill or know-how or authority to do something; \"able to swim\"; \"she was able to program her computer\"; \"we were at last able to buy a car\"; \"able to get a grant for the project\"'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = swn_lines[0].strip(\"\\t\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "data = [line.strip(\"\\t\") for line in swn_lines]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a\\t00001740\\t0.125\\t0\\table#1\\t(usually followed by `to\\') having the necessary means or skill or know-how or authority to do something; \"able to swim\"; \"she was able to program her computer\"; \"we were at last able to buy a car\"; \"able to get a grant for the project\"',\n",
       " 'a\\t00002098\\t0\\t0.75\\tunable#1\\t(usually followed by `to\\') not having the necessary means or skill or know-how; \"unable to get to town without a car\"; \"unable to obtain funds\"',\n",
       " 'a\\t00002312\\t0\\t0\\tdorsal#2 abaxial#1\\tfacing away from the axis of an organ or organism; \"the abaxial surface of a leaf is the underside or side facing away from the stem\"']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-4-f8cf4dc61bd1>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-f8cf4dc61bd1>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    for i, line in enumerate(swn_lines):\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "for i, line in enumerate(swn_lines):\n",
    "    data = line.strip(\"\\t\")\n",
    "    score = (data[2], data[3])\n",
    "    line_words = data[4]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class senti_wordnet:\n",
    "    def __init__(self):\n",
    "        print(\"initializing sentiwordnet 3.0\")\n",
    "        fswn = open(#open sentiment wordnet 3.0 file\n",
    "            \"/home/yi/Music/Sentiment-Analysis/SentiWordNet_3.0/swn/www/admin/dump/SentiWordNet_3.0.0_20130122.txt\")\n",
    "        swn_lines = [line.strip() for line in fswn.readlines()]\n",
    "        fswn.close()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-22-ff53536926fd>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-22-ff53536926fd>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    data.\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# calculate popularity according the reviews.pdf, section 3 - Measures\n",
    "# set desofault start date as the eailest date and default end date as the latest date for given reviews\n",
    "startDate = \"\"\n",
    "endDate = \"\"\n",
    "\n",
    "# create review text feature vectors\n",
    "reviewVectors = TfidfVectorizer(min_df= 5, max_df= 0.8, sublinear_tf = True, use_idf= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getArgsFromCommand():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-startDate\", help=\"set start date for finding reviews\")\n",
    "    parser.add_argument(\"-endDate\", help=\"set end date for find reviews\")\n",
    "    args = parser.parse_args()\n",
    "    try:\n",
    "        startDate = args.startDate\n",
    "        endDate = args.endDate\n",
    "        return startDate, endDate\n",
    "    except args as identifier:\n",
    "        print(\"input parameter error, input like: python xxxxxxxx.py -startDate [yyyy.mm,dd] -o [yyyy.mm.dd]\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#implement different calculating sentiment methods\n",
    "\n",
    "#sentstrength calculation method, function which accepts users' review for hotels,\n",
    "# return two numbers[postive sentiment score, negative sentiment score]\n",
    "def sentStrength(string review):\n",
    "    posSentScore = 0\n",
    "    negSentScore = 0\n",
    "\n",
    "    return posSentScore, negSentScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#SVM\n",
    "def sentSVM(String review):\n",
    "    sentClass = [\"Pos\", \"Neg\"]\n",
    "    \n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    \n",
    "    test_data = []\n",
    "    test_labels = []\n",
    "    \n",
    "    \n",
    "# Create feature vectors\n",
    "    \n",
    "    \n",
    "    posSentScore = 0\n",
    "    negSentScore = 0\n",
    "\n",
    "    return posSentScore, negSentScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Naïve Bayes\n",
    "def sentNaiveBayes(String review):\n",
    "    posSentScore = 0\n",
    "    negSentScore = 0\n",
    "\n",
    "    return posSentScore, negSentScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def stanfordNLPSentParse(String review):\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def googleNLPSentParse(String review):\n",
    "    return None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
